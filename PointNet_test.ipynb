{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PointNet_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/g4aidl-upc-winter-2020/3D-Shape-classification/blob/main/PointNet_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmVCqPwQbzhU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d3e013-5591-4305-996e-519d94a8c49c"
      },
      "source": [
        "# Install all needed packages from PyG:\r\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\r\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\r\n",
        "!pip install -q torch-geometric"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.6MB 5.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 3.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 5.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 6.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 7.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoFs-MOrKVw8"
      },
      "source": [
        "import torch\r\n",
        "from torch_geometric.datasets import ModelNet\r\n",
        "from torch_geometric.data import DataLoader\r\n",
        "from torch_geometric.utils import to_dense_batch\r\n",
        "import torch_geometric.transforms as T\r\n",
        "from torch_geometric.transforms import SamplePoints, NormalizeScale\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import sys\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhBEyBDMKTJU"
      },
      "source": [
        "## Set a fixed seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTbPwkkZKTR6"
      },
      "source": [
        "seed = 42\r\n",
        "\r\n",
        "#Controlling sources of randomness\r\n",
        "torch.manual_seed(seed)  #Sets the seed for generating random numbers for all devices (both CPU and CUDA)\r\n",
        "\r\n",
        "#CUDA convolution benchmarking\r\n",
        "torch.backends.cudnn.benchmark = False #ensures that CUDA selects the same algorithm each time an application is run\r\n",
        "\r\n",
        "#Avoiding nondeterministic algorithms\r\n",
        "torch.use_deterministic_algorithms(True) #use “deterministic” algorithms (given the same input always produce the same output)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjmlxjFGO6UW"
      },
      "source": [
        "### Import drive folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3an0luY9O7Dm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef7334d-8579-422b-8fb1-8074e2a16f26"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCrbSl8Gl7J_"
      },
      "source": [
        "# PointNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCAtJTBHOWA-"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7S0n1sucFeF"
      },
      "source": [
        "# Import ModelNet10 dataset from PyG\r\n",
        "test_dataset = ModelNet(root='/content/drive/MyDrive/Proyecto/Colabs/ModelNet', name=\"10\", train=False, pre_transform=T.SamplePoints(num=1024))  #test dataset"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU1KoIQPdsxH",
        "outputId": "b99884fa-ff9d-4c5c-9f2a-51f7471f3556"
      },
      "source": [
        "print('Dataset info:')\r\n",
        "print('--------------')\r\n",
        "print('Test dataset size: ', len(test_dataset))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset info:\n",
            "--------------\n",
            "Test dataset size:  908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsnpSL0AwEyJ"
      },
      "source": [
        "### Normalize Input points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWNS-uc2tWsi"
      },
      "source": [
        "#Centers and normalizes node positions to the interval (-1,1) \r\n",
        "test_dataset.transform = NormalizeScale()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbyoTU29DvDy"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVADHsQOLE5R"
      },
      "source": [
        "### Make sure your runtime has a GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoO0XuudLFOT"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "assert not device.type == 'cpu', \"Change Runtime Type -> GPU\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkyrnD7K3IaE"
      },
      "source": [
        "### Loading the model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0tg178AB8g1"
      },
      "source": [
        "#We include a new file path that will point to modules the we want to import\r\n",
        "sys.path.append('/content/drive/MyDrive/Proyecto/Colabs/architectures/PointNet')  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVUeUEIwGeu7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "236e04d8-b17d-4de6-be6d-6a04a316d187"
      },
      "source": [
        "#Import the model from a python script\r\n",
        "from PointNet_Architecture import ClassificationPointNet\r\n",
        "model = ClassificationPointNet()  #Instantiate the model\r\n",
        "model.to(device)    # Pass the model to GPU(device)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassificationPointNet(\n",
              "  (transform): Transform(\n",
              "    (input_transform): Tnet(\n",
              "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
              "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
              "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
              "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (feature_transform): Tnet(\n",
              "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
              "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
              "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (fc3): Linear(in_features=256, out_features=4096, bias=True)\n",
              "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
              "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
              "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K85UkXed3ZB_"
      },
      "source": [
        "### Loading best parameters from training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krkfMn-rs-yI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d6ce56-bef3-4639-f0b9-3d6d63a7007f"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Proyecto/Colabs/experiments/logs/PointNet/train/best_params.pt')) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQLy12AoN6Lj"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhMOsGbtC8GR"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nlm2mlk4tOYd"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMqqd2nEDvjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8adcdf81-239a-4e55-c364-4e145d8ab9d7"
      },
      "source": [
        "model.eval()\r\n",
        "with torch.no_grad():\r\n",
        "  total=correct=0\r\n",
        "  all_preds = []\r\n",
        "  all_labels = []\r\n",
        "  for data in test_loader:\r\n",
        "      inputs = to_dense_batch(data.pos, batch=data.batch)  #return a tuple where in the first position there are the points of every pointcloud in the batch \r\n",
        "\r\n",
        "      output = model(inputs[0].to(device).float().transpose(1,2))  #Pass the inputs through the network and compute the outputs\r\n",
        "      _, preds = torch.max(output, 1) # We get the maximum prediction value (correct category) for each pointcloud in the batch\r\n",
        "      total += data.y.size(0)  # total number of samples in the test_loader\r\n",
        "      correct += (preds == data.y.to(device)).sum().item()  #number of total correct predictions in the test_loader\r\n",
        "      \r\n",
        "      all_preds += list(preds.cpu().numpy())\r\n",
        "      all_labels += list(data.y.cpu().numpy())\r\n",
        "\r\n",
        "val_acc = 100. * (correct / total)\r\n",
        "print('Valid accuracy: {:.2f} %'.format(val_acc))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valid accuracy: 90.97 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRx68XLhZjKX"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGI1hBWAG-Ld"
      },
      "source": [
        "###Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm4bRQPfZzuW"
      },
      "source": [
        "#ClassesNames = ['Bathtub', 'Bed', 'Chair', 'Desk', 'Dresser', 'Monitor', 'Night_Stand', 'Sofa', 'Table', 'Toilet']\r\n",
        "#Classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC5MABT7HEaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ae39839-53c2-4cf3-bac7-170bb84fba85"
      },
      "source": [
        "cm = confusion_matrix(all_labels, all_preds);\r\n",
        "cm"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 47,   1,   0,   0,   0,   0,   0,   0,   1,   1],\n",
              "       [  0,  98,   0,   0,   0,   0,   0,   0,   2,   0],\n",
              "       [  0,   0, 100,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   1,   0,  73,   1,   0,   1,   5,   5,   0],\n",
              "       [  0,   0,   0,   1,  75,   0,   9,   0,   1,   0],\n",
              "       [  0,   0,   0,   0,   0,  99,   1,   0,   0,   0],\n",
              "       [  0,   1,   0,   1,  14,   0,  64,   0,   6,   0],\n",
              "       [  0,   0,   0,   1,   0,   0,   1,  98,   0,   0],\n",
              "       [  0,   0,   0,  26,   0,   0,   0,   0,  74,   0],\n",
              "       [  0,   1,   1,   0,   0,   0,   0,   0,   0,  98]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvxmoHKmZ23l"
      },
      "source": [
        "### Precision and Recall "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJeOSTjEED6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c88722e-3ca2-4f7a-9ec5-d124734938ad"
      },
      "source": [
        "##Function to compute Precision and recall scores per class\r\n",
        "\r\n",
        "dim = cm.shape[0]\r\n",
        "ClassesNames = ['Bathtub', 'Bed', 'Chair', 'Desk', 'Dresser', 'Monitor', 'Night_Stand', 'Sofa', 'Table', 'Toilet']\r\n",
        "# Precision = TP / (TP + FP)\r\n",
        "# Recall = TP / (TP + FN)\r\n",
        "Precision = []\r\n",
        "Recall = []\r\n",
        "Correct = 0\r\n",
        "Samples = 0\r\n",
        "PrecisionWAvg = 0\r\n",
        "RecallWAvg = 0\r\n",
        "for i in range(0, dim):\r\n",
        "  TP = cm[i,i]  #Diagonal value (TP)\r\n",
        "  FPc = 0\r\n",
        "  FNc = 0\r\n",
        "  for j in range(0, dim):\r\n",
        "    Samples += cm[i,j]\r\n",
        "    FNc += cm[i,j]  #Add all line values\r\n",
        "    FPc += cm[j,i]  #Add all column values\r\n",
        "  FN = FNc - TP   #Substract diagonal value (TP)\r\n",
        "  FP = FPc - TP   #Substract diagonal value (TP)\r\n",
        "  Correct += TP\r\n",
        "  if TP==0:\r\n",
        "    Precision.append(0)\r\n",
        "    Recall.append(0)\r\n",
        "  else:  \r\n",
        "    Precision.append(100*(TP/(TP+FP)))\r\n",
        "    Recall.append(100*(TP/(TP+FN)))\r\n",
        "    PrecisionWAvg+=100*(TP/(TP+FP))*(TP+FN)\r\n",
        "    RecallWAvg+=100*(TP/(TP+FN))*(TP+FN)\r\n",
        "\r\n",
        "  print(ClassesNames[i], \"\\n\\tPrecision: {:.2f}% \\tRecall: {:.2f}%\".format(Precision[i],Recall[i]))\r\n",
        "  print(\"\\tTP:\", TP,\"  FP:\", FP,\"  FN:\", FN,\"  Samples in Test:\",TP+FN)\r\n",
        "\r\n",
        "print(\"\\nTOTAL Accuracy: {:.2f}%\".format(100*Correct/Samples),\"  Samples in Test: \", Samples,\"  Correct Predictions: \", Correct)\r\n",
        "print(\"Avg. Weighted Precision: {:.2f}% \\tAvg. Weighted Recall: {:.2f}%\\n\".format(PrecisionWAvg/Samples, RecallWAvg/Samples))\r\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bathtub \n",
            "\tPrecision: 100.00% \tRecall: 94.00%\n",
            "\tTP: 47   FP: 0   FN: 3   Samples in Test: 50\n",
            "Bed \n",
            "\tPrecision: 96.08% \tRecall: 98.00%\n",
            "\tTP: 98   FP: 4   FN: 2   Samples in Test: 100\n",
            "Chair \n",
            "\tPrecision: 99.01% \tRecall: 100.00%\n",
            "\tTP: 100   FP: 1   FN: 0   Samples in Test: 100\n",
            "Desk \n",
            "\tPrecision: 71.57% \tRecall: 84.88%\n",
            "\tTP: 73   FP: 29   FN: 13   Samples in Test: 86\n",
            "Dresser \n",
            "\tPrecision: 83.33% \tRecall: 87.21%\n",
            "\tTP: 75   FP: 15   FN: 11   Samples in Test: 86\n",
            "Monitor \n",
            "\tPrecision: 100.00% \tRecall: 99.00%\n",
            "\tTP: 99   FP: 0   FN: 1   Samples in Test: 100\n",
            "Night_Stand \n",
            "\tPrecision: 84.21% \tRecall: 74.42%\n",
            "\tTP: 64   FP: 12   FN: 22   Samples in Test: 86\n",
            "Sofa \n",
            "\tPrecision: 95.15% \tRecall: 98.00%\n",
            "\tTP: 98   FP: 5   FN: 2   Samples in Test: 100\n",
            "Table \n",
            "\tPrecision: 83.15% \tRecall: 74.00%\n",
            "\tTP: 74   FP: 15   FN: 26   Samples in Test: 100\n",
            "Toilet \n",
            "\tPrecision: 98.99% \tRecall: 98.00%\n",
            "\tTP: 98   FP: 1   FN: 2   Samples in Test: 100\n",
            "\n",
            "TOTAL Accuracy: 90.97%   Samples in Test:  908   Correct Predictions:  826\n",
            "Avg. Weighted Precision: 91.19% \tAvg. Weighted Recall: 90.97%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
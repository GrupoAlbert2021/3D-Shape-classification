{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_PointNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/g4aidl-upc-winter-2020/3D-Shape-classification/blob/main/Test_PointNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmVCqPwQbzhU"
      },
      "source": [
        "# Install all needed packages from PyG:\r\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\r\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\r\n",
        "!pip install -q torch-geometric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoFs-MOrKVw8"
      },
      "source": [
        "import torch\r\n",
        "from torch_geometric.datasets import ModelNet\r\n",
        "from torch_geometric.data import DataLoader\r\n",
        "from torch_geometric.utils import to_dense_batch\r\n",
        "import torch_geometric.transforms as T\r\n",
        "from torch_geometric.transforms import SamplePoints, NormalizeScale\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import sys\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhBEyBDMKTJU"
      },
      "source": [
        "## Set a fixed seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTbPwkkZKTR6"
      },
      "source": [
        "seed = 42\r\n",
        "\r\n",
        "#Controlling sources of randomness\r\n",
        "torch.manual_seed(seed)  #Sets the seed for generating random numbers for all devices (both CPU and CUDA)\r\n",
        "\r\n",
        "#CUDA convolution benchmarking\r\n",
        "torch.backends.cudnn.benchmark = False #ensures that CUDA selects the same algorithm each time an application is run\r\n",
        "\r\n",
        "#Avoiding nondeterministic algorithms\r\n",
        "torch.use_deterministic_algorithms(True) #use “deterministic” algorithms (given the same input always produce the same output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjmlxjFGO6UW"
      },
      "source": [
        "### Import drive folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3an0luY9O7Dm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab75420e-36c5-4c9b-861c-ca291de265bf"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCrbSl8Gl7J_"
      },
      "source": [
        "# PointNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCAtJTBHOWA-"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7S0n1sucFeF"
      },
      "source": [
        "# Import ModelNet10 dataset from PyG\r\n",
        "test_dataset = ModelNet(root='/content/drive/MyDrive/Proyecto/Colabs/ModelNet', name=\"10\", train=False, pre_transform=T.SamplePoints(num=1024))  #test dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU1KoIQPdsxH",
        "outputId": "0d2e0d92-5ad1-4e6c-b284-643e8cac6a09"
      },
      "source": [
        "print('Dataset info:')\r\n",
        "print('--------------')\r\n",
        "print('Test dataset size: ', len(test_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset info:\n",
            "--------------\n",
            "Test dataset size:  908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsnpSL0AwEyJ"
      },
      "source": [
        "### Normalize Input points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWNS-uc2tWsi"
      },
      "source": [
        "#Centers and normalizes node positions to the interval (-1,1) \r\n",
        "test_dataset.transform = NormalizeScale()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbyoTU29DvDy"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVADHsQOLE5R"
      },
      "source": [
        "### Make sure your runtime has a GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoO0XuudLFOT"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "assert not device.type == 'cpu', \"Change Runtime Type -> GPU\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkyrnD7K3IaE"
      },
      "source": [
        "### Loading the model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0tg178AB8g1"
      },
      "source": [
        "#We include a new file path that will point to modules the we want to import\r\n",
        "sys.path.append('/content/drive/MyDrive/Proyecto/Colabs/Architectures/PointNet')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVUeUEIwGeu7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d855e2-d46e-4953-fbfd-4d7e8ed54959"
      },
      "source": [
        "#Import the model from a python script\r\n",
        "from PointNet_Architecture import ClassificationPointNet\r\n",
        "model = ClassificationPointNet()  #Instantiate the model\r\n",
        "model.to(device)    # Pass the model to GPU(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassificationPointNet(\n",
              "  (transform): Transform(\n",
              "    (input_transform): Tnet(\n",
              "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
              "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
              "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
              "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (feature_transform): Tnet(\n",
              "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
              "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
              "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (fc3): Linear(in_features=256, out_features=4096, bias=True)\n",
              "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
              "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
              "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
              "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
              "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K85UkXed3ZB_"
      },
      "source": [
        "### Loading best parameters from training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krkfMn-rs-yI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575bab15-aebe-4b16-aefa-a69a4565e61b"
      },
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Proyecto/Colabs/logs/PointNet/train/best_params.pt'))  #change folder name for testing a different training"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQLy12AoN6Lj"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhMOsGbtC8GR"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nlm2mlk4tOYd"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMqqd2nEDvjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "775cf0ba-6d64-437d-f989-efd67d9c2304"
      },
      "source": [
        "model.eval()\r\n",
        "with torch.no_grad():\r\n",
        "  total=correct=0\r\n",
        "  all_preds = []\r\n",
        "  all_labels = []\r\n",
        "  for data in test_loader:\r\n",
        "      inputs = to_dense_batch(data.pos, batch=data.batch)  #return a tuple where in the first position there are the points of every pointcloud in the batch \r\n",
        "\r\n",
        "      output = model(inputs[0].to(device).float().transpose(1,2))  #Pass the inputs through the network and compute the outputs\r\n",
        "      _, preds = torch.max(output, 1) # We get the maximum prediction value (correct category) for each pointcloud in the batch\r\n",
        "      total += data.y.size(0)  # total number of samples in the test_loader\r\n",
        "      correct += (preds == data.y.to(device)).sum().item()  #number of total correct predictions in the test_loader\r\n",
        "      \r\n",
        "      all_preds += list(preds.cpu().numpy())\r\n",
        "      all_labels += list(data.y.cpu().numpy())\r\n",
        "\r\n",
        "val_acc = 100. * (correct / total)\r\n",
        "print('Valid accuracy: {:.2f} %'.format(val_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valid accuracy: 91.41 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRx68XLhZjKX"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGI1hBWAG-Ld"
      },
      "source": [
        "###Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lm4bRQPfZzuW"
      },
      "source": [
        "#ClassesNames = ['Bathtub', 'Bed', 'Chair', 'Desk', 'Dresser', 'Monitor', 'Night_Stand', 'Sofa', 'Table', 'Toilet']\r\n",
        "#Classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC5MABT7HEaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab1459be-f984-4213-c2b0-a394b074ebe1"
      },
      "source": [
        "cm = confusion_matrix(all_labels, all_preds);\r\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[44,  5,  0,  0,  0,  0,  0,  0,  1,  0],\n",
              "       [ 0, 99,  0,  0,  0,  0,  0,  0,  1,  0],\n",
              "       [ 0,  1, 99,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 0,  0,  0, 79,  1,  0,  0,  3,  3,  0],\n",
              "       [ 0,  0,  0,  1, 69,  1, 14,  0,  1,  0],\n",
              "       [ 0,  0,  0,  0,  0, 98,  2,  0,  0,  0],\n",
              "       [ 0,  1,  0,  0, 13,  0, 66,  0,  6,  0],\n",
              "       [ 0,  0,  0,  2,  0,  0,  0, 98,  0,  0],\n",
              "       [ 0,  0,  0, 20,  0,  0,  0,  0, 80,  0],\n",
              "       [ 0,  0,  2,  0,  0,  0,  0,  0,  0, 98]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvxmoHKmZ23l"
      },
      "source": [
        "### Precision and Recall "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJeOSTjEED6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7a61da-2e62-4e79-b76a-5cff178c5877"
      },
      "source": [
        "##Function to compute Precision and recall scores per class\r\n",
        "\r\n",
        "dim = cm.shape[0]\r\n",
        "ClassesNames = ['Bathtub', 'Bed', 'Chair', 'Desk', 'Dresser', 'Monitor', 'Night_Stand', 'Sofa', 'Table', 'Toilet']\r\n",
        "# Precision = TP / (TP + FP)\r\n",
        "# Recall = TP / (TP + FN)\r\n",
        "Precision = []\r\n",
        "Recall = []\r\n",
        "Correct = 0\r\n",
        "Samples = 0\r\n",
        "PrecisionWAvg = 0\r\n",
        "RecallWAvg = 0\r\n",
        "for i in range(0, dim):\r\n",
        "  TP = cm[i,i]  #Diagonal value (TP)\r\n",
        "  FPc = 0\r\n",
        "  FNc = 0\r\n",
        "  for j in range(0, dim):\r\n",
        "    Samples += cm[i,j]\r\n",
        "    FNc += cm[i,j]  #Add all line values\r\n",
        "    FPc += cm[j,i]  #Add all column values\r\n",
        "  FN = FNc - TP   #Substract diagonal value (TP)\r\n",
        "  FP = FPc - TP   #Substract diagonal value (TP)\r\n",
        "  Correct += TP\r\n",
        "  if TP==0:\r\n",
        "    Precision.append(0)\r\n",
        "    Recall.append(0)\r\n",
        "  else:  \r\n",
        "    Precision.append(100*(TP/(TP+FP)))\r\n",
        "    Recall.append(100*(TP/(TP+FN)))\r\n",
        "    PrecisionWAvg+=100*(TP/(TP+FP))*(TP+FN)\r\n",
        "    RecallWAvg+=100*(TP/(TP+FN))*(TP+FN)\r\n",
        "\r\n",
        "  print(ClassesNames[i], \"\\n\\tPrecision: {:.2f}% \\tRecall: {:.2f}%\".format(Precision[i],Recall[i]))\r\n",
        "  print(\"\\tTP:\", TP,\"  FP:\", FP,\"  FN:\", FN,\"  Samples in Test:\",TP+FN)\r\n",
        "\r\n",
        "print(\"\\nTOTAL Accuracy: {:.2f}%\".format(100*Correct/Samples),\"  Samples in Test: \", Samples,\"  Correct Predictions: \", Correct)\r\n",
        "print(\"Avg. Weighted Precision: {:.2f}% \\tAvg. Weighted Recall: {:.2f}%\\n\".format(PrecisionWAvg/Samples, RecallWAvg/Samples))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bathtub \n",
            "\tPrecision: 100.00% \tRecall: 88.00%\n",
            "\tTP: 44   FP: 0   FN: 6   Samples in Test: 50\n",
            "Bed \n",
            "\tPrecision: 93.40% \tRecall: 99.00%\n",
            "\tTP: 99   FP: 7   FN: 1   Samples in Test: 100\n",
            "Chair \n",
            "\tPrecision: 98.02% \tRecall: 99.00%\n",
            "\tTP: 99   FP: 2   FN: 1   Samples in Test: 100\n",
            "Desk \n",
            "\tPrecision: 77.45% \tRecall: 91.86%\n",
            "\tTP: 79   FP: 23   FN: 7   Samples in Test: 86\n",
            "Dresser \n",
            "\tPrecision: 83.13% \tRecall: 80.23%\n",
            "\tTP: 69   FP: 14   FN: 17   Samples in Test: 86\n",
            "Monitor \n",
            "\tPrecision: 98.99% \tRecall: 98.00%\n",
            "\tTP: 98   FP: 1   FN: 2   Samples in Test: 100\n",
            "Night_Stand \n",
            "\tPrecision: 80.49% \tRecall: 76.74%\n",
            "\tTP: 66   FP: 16   FN: 20   Samples in Test: 86\n",
            "Sofa \n",
            "\tPrecision: 97.03% \tRecall: 98.00%\n",
            "\tTP: 98   FP: 3   FN: 2   Samples in Test: 100\n",
            "Table \n",
            "\tPrecision: 86.96% \tRecall: 80.00%\n",
            "\tTP: 80   FP: 12   FN: 20   Samples in Test: 100\n",
            "Toilet \n",
            "\tPrecision: 100.00% \tRecall: 98.00%\n",
            "\tTP: 98   FP: 0   FN: 2   Samples in Test: 100\n",
            "\n",
            "TOTAL Accuracy: 91.41%   Samples in Test:  908   Correct Predictions:  830\n",
            "Avg. Weighted Precision: 91.60% \tAvg. Weighted Recall: 91.41%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}